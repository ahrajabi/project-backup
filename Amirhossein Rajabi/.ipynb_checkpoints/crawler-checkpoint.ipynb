{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import redis\n",
    "import time\n",
    "import numpy as np\n",
    "import lda\n",
    "import lda.datasets\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = redis.StrictRedis()\n",
    "swfa = pd.read_csv('../dataset/stopwords.csv' , header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82120000\n",
      "82120500\n",
      "82121000\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for i in range(82120000,82154440):#range(82120000,82154440):\n",
    "    if i % 500 == 0:\n",
    "        print(i)\n",
    "    if r.exists('irna#'+str(i)):\n",
    "        continue\n",
    "    url = 'http://www.irna.ir/fa/News/'+str(i)+'/'\n",
    "    page = requests.get(url).text\n",
    "    soup = bs(page , \"html.parser\")\n",
    "    if soup :\n",
    "        body = soup.find('div',class_='BodyText')\n",
    "        if body:\n",
    "            body = body.find('p')\n",
    "            r.set('irna#'+str(i) , body.text)\n",
    "        else:\n",
    "            r.set('irna#'+str(i) , \"None\")\n",
    "    else:\n",
    "        r.set('irna#'+str(i) , \"None\")\n",
    "print(\"--- %s seconds ---\" % ( time.time() - start_time ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "Could not find stanford-postagger.jar jar file at ../dataset/stanford-postagger.jar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-31492ac9acf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhazm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPOSTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../dataset/tagger/postagger.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStanfordPOSTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_filename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../dataset/persian.tagger'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_jar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../dataset/stanford-postagger.jar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mlean_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mclean_train_original\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jupuser/vir/lib/python3.5/site-packages/hazm/POSTagger.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_filename, path_to_jar, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_jar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SEPARATOR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstanford\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStanfordPOSTagger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_filename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_jar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_to_jar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jupuser/vir/lib/python3.5/site-packages/nltk/tag/stanford.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_filename, path_to_jar, encoding, verbose, java_options)\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_JAR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_jar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0msearchpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_stanford_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 verbose=verbose)\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         self._stanford_model = find_file(model_filename,\n",
      "\u001b[0;32m/home/jupuser/vir/lib/python3.5/site-packages/nltk/__init__.py\u001b[0m in \u001b[0;36mfind_jar\u001b[0;34m(name_pattern, path_to_jar, env_vars, searchpath, url, verbose, is_regex)\u001b[0m\n\u001b[1;32m    678\u001b[0m         searchpath=(), url=None, verbose=True, is_regex=False):\n\u001b[1;32m    679\u001b[0m     return next(find_jar_iter(name_pattern, path_to_jar, env_vars,\n\u001b[0;32m--> 680\u001b[0;31m                          searchpath, url, verbose, is_regex))\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jupuser/vir/lib/python3.5/site-packages/nltk/__init__.py\u001b[0m in \u001b[0;36mfind_jar_iter\u001b[0;34m(name_pattern, path_to_jar, env_vars, searchpath, url, verbose, is_regex)\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             raise LookupError('Could not find %s jar file at %s' %\n\u001b[0;32m--> 596\u001b[0;31m                             (name_pattern, path_to_jar))\n\u001b[0m\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;31m# Check environment variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: Could not find stanford-postagger.jar jar file at ../dataset/stanford-postagger.jar"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "from hazm import *\n",
    "tagger = POSTagger(model='../dataset/tagger/postagger.model')\n",
    "tagger = StanfordPOSTagger(model_filename='../dataset/persian.tagger', path_to_jar='../dataset/stanford-postagger.jar')\n",
    "lean_train = []\n",
    "clean_train_original = []\n",
    "cnt = 0\n",
    "for i in r.keys(pattern='irna#82120000'):\n",
    "    body = r.get(i)\n",
    "    cnt += 1\n",
    "    if cnt % 50 == 0:\n",
    "        print(cnt)\n",
    "    if body == 'None':\n",
    "        continue\n",
    "    body = body.decode('utf-8')\n",
    "    print(body)\n",
    "    norm = Normalizer()\n",
    "    stemmer = Stemmer()\n",
    "    lemmatizer = Lemmatizer()\n",
    "    body = norm.normalize(body)\n",
    "    body = word_tokenize(body)\n",
    "    words = [w for w in body if not w in list(swfa[0])]\n",
    "    for idx , j in enumerate(words):\n",
    "#        words[idx] = stemmer.stem(j)\n",
    "        k = tagger.tag([words[idx]])\n",
    "        print(k)\n",
    "        if k[0][1] in [\"PUNC\",\"NUM\",\"V\",\"ADV\",\"AJ\"] :\n",
    "            words[idx] = ''\n",
    "        words[idx] = lemmatizer.lemmatize(words[idx] , post =k[0][1])\n",
    "        #print(tagger.tag(j))\n",
    "    clean_train_original.append(words)\n",
    "    clean_train.append( \" \".join( words ) )\n",
    "#    print(clean_train)\n",
    "\n",
    "print(\"--- %s seconds ---\" % ( time.time() - start_time ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 500)\n",
    "train_data_features_original = vectorizer.fit_transform(clean_train)\n",
    "train_data_features = train_data_features_original.toarray()\n",
    "vocab = vectorizer.get_feature_names()\n",
    "print(len(vocab))\n",
    "dist = np.sum(train_data_features, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lda.lda.LDA at 0x7f8e59a78b00>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lda.LDA(n_topics = 50 , n_iter=300, random_state=1)\n",
    "model.fit(train_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: دولت کشور حقوق نظام قانون جمهوری رئیس مدیر پرداخت\n",
      "Topic 1: افراد وجود کار سال زمان دلیل قرار دست فرد\n",
      "Topic 2: آمریکا روزنامه عنوان گزارش کره کشور خبر شبکه اعلام\n",
      "Topic 3: گروه عراق نیرو داعش سوریه شهر عملیات نظام گزارش\n",
      "Topic 4: آتش سوخت حادثه جاده نیرو روز ساعت علت زمین\n",
      "Topic 5: کشور توسعه سرمایه بخش ایجاد زمینه حوزه رشد فعالیت\n",
      "Topic 6: انقلاب رهبر الاسلام جمعه اشاره حجت امام الله جامعه\n",
      "Topic 7: خراسان قانون رضوی نامه نفر نظر ادامه کشور سازمان\n",
      "Topic 8: زندان کمک ریال جشن نفر خیر ستاد استان خانواده\n",
      "Topic 9: حزب انتخابات کار وزیر حضور حمایت رهبر روز سال\n",
      "Topic 10: استان ثبت سال سازمان انداز انداخت اداره انجام اظهار\n",
      "Topic 11: سال درصد گذشته اصفهان نفر افزایش میزان آمار حدود\n",
      "Topic 12: اسلام جهان مسلمان ادامه بیان ایران دشمن ملت روز\n",
      "Topic 13: بحرین رژیم آل شیخ قاسم عیسی خلیفه تابعیت کشور\n",
      "Topic 14: اتحادیه اروپا انگلیس خروج کشور پرس پرسید بریتانیا برگزیت\n",
      "Topic 15: کرمان سرباز فارس حادثه شیراز اتوبوس خوزستان نفر دستگاه\n",
      "Topic 16: منطقه نیرو دریا کشور چین نظام مناطق مرز سال\n",
      "Topic 17: استان استاندار بوشهر سمنان مدیرکل بیان مدیر نشست کشور\n",
      "Topic 18: تیم ورزش فوتبال لیگ باشگاه جوان فصل رشته هیات\n",
      "Topic 19: شهرستان روستا کیلومتر فرماندار نفر جمعیت آذربایجان واقع ایرنا\n",
      "Topic 20: تیم بازی رقابت دیدار مسابقات مرحله ایران های حضور\n",
      "Topic 21: محیط زیست none حفاظت استان گونه مدیرکل سازمان منطقه\n",
      "Topic 22: شب ماه رمضان قدر قرآن مبارک مراسم نماز امام\n",
      "Topic 23: شهر شهردار شهروند شورا فضا زمین منطقه حاشیه مدیریت\n",
      "Topic 24: آب استان کشاورزی هکتار مصرف منابع شرکت روستا اراضی\n",
      "Topic 25: وزیر رئیس کشور سفر جمهوری دیدار امور ترکیه فرانسه\n",
      "Topic 26: مواد مبارزه اعتیاد مصرف پیشگیر جامعه آسیب خانواده استان\n",
      "Topic 27: کاهش بازار درصد قیمت نرخ افزایش ریال دلار ارزش\n",
      "Topic 28: مجلس مازندران کمیسیون شورا نمایندگان نماینده دوره استان عضو\n",
      "Topic 29: کشور ها بحران مدیریت توجه اقدامات انجام قرار تاکید\n",
      "Topic 30: واحد بانک تسهیلات مسکن مشکلات استان پرداخت ریال مشکل\n",
      "Topic 31: پرونده دستگاه دادگستری قوه سال رسیدگی کاهش استان حقوق\n",
      "Topic 32: شهید شهدا شهادت روز قدس هفته انقلاب تیر قوه\n",
      "Topic 33: رسان رساند اطلاع پایگاه ایرنا روز گزارش روابط ها\n",
      "Topic 34: گردشگری دست ساخت صنایع ساز خانه ایجاد ظرفیت حوزه\n",
      "Topic 35: طرح اجرا پروژه سال ریال اعتبار بهره کار ساخت\n",
      "Topic 36: اقتصاد مقاومت برنامه دولت بخش طرح اجرا تحقق توسعه\n",
      "Topic 37: سازمان پاکستان کشور همکار هند شانگهای ایران عضو افغانستان\n",
      "Topic 38: آموزش دانش پرورش برنامه دوره نفر استان کانون فعالیت\n",
      "Topic 39: تهران روز ساعت ایرنا شرکت خبر برنامه شنبه گزارش\n",
      "Topic 40: دانشگاه قرآن نمایشگاه کتاب استاد موسسه علوم فرهنگ رشته\n",
      "Topic 41: کار فرهنگ جامعه رسانه تلاش نقش حوزه مسئول بیان\n",
      "Topic 42: روز هوا استان سیستان گذشته شرایط افزایش ایرنا متر\n",
      "Topic 43: پلیس خودرو قاچاق کالا کشف شناسایی فرمانده دستگاه شهرستان\n",
      "Topic 44: شرکت تولید صنعت صادرات کشور نفت بازار معدن محصولات\n",
      "Topic 45: کودک خانواده زن جوان جامعه فضا زندگی برنامه افراد\n",
      "Topic 46: امام حسن حضرت علی مراسم اهل بیت سید محمد\n",
      "Topic 47: ایران کشور روسیه المللی سال عربستان جهان جمهوری آمریکا\n",
      "Topic 48: سازمان شورا برنامه جلسه گزارش دستگاه کمیته نهاد ملل\n",
      "Topic 49: پزشک بیمار سلامت بهداشت قم بیمارستان درمان دانشگاه خون\n"
     ]
    }
   ],
   "source": [
    "topic_word = model.topic_word_  # model.components_ also works\n",
    "n_top_words = 10\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    np.array(vocab)[np.argsort(topic_dist)]\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-n_top_words:-1]\n",
    "    print('Topic {}: {}'.format(i, ' '.join(topic_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models , similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(clean_train_original)\n",
    "corpus = [dictionary.doc2bow(text) for text in clean_train_original]\n",
    "tfidf = models.TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf[corpus]\n",
    "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=10) # initialize an LSI transformation\n",
    "corpus_lsi = lsi[corpus_tfidf] # create a double wrapper over the original corpus: bow->tfidf->fold-in-lsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000*\"None\" + 0.000*\"اسپانیا\" + -0.000*\"رایانه\" + -0.000*\"ابررایانه\" + -0.000*\"استخر\" + -0.000*\"آمریکا\" + -0.000*\"آلمان\" + -0.000*\"چین\" + -0.000*\"ناتو\" + 0.000*\"وزارت\"\n",
      "----------\n",
      "0.851*\"\" + 0.083*\"اقتصاد\" + 0.069*\"مقاومت\" + 0.068*\"گردشگری\" + 0.067*\"طرح\" + 0.066*\"استان\" + 0.065*\"کشور\" + 0.056*\"شهر\" + 0.055*\"شهرستان\" + 0.053*\"خونه\"\n",
      "----------\n",
      "0.707*\"خونه\" + 0.319*\"تیم\" + 0.311*\"لیگ\" + 0.213*\"مازندران\" + 0.199*\"بازیکن\" + 0.126*\"فوتبال\" + 0.115*\"باشگاه\" + 0.101*\"سرمربی\" + 0.089*\"مرزبان\" + 0.072*\"کریم\"\n",
      "----------\n",
      "-0.488*\"بحرین\" + -0.229*\"عیسی\" + 0.192*\"اقتصاد\" + -0.186*\"شیخ\" + 0.177*\"گردشگری\" + 0.172*\"مقاومت\" + -0.143*\"قاسم\" + 0.111*\"تعاون\" + -0.100*\"حزب\" + 0.099*\"بنا\"\n",
      "----------\n",
      "-0.295*\"اقتصاد\" + 0.290*\"گردشگری\" + -0.274*\"مقاومت\" + 0.241*\"بنا\" + 0.235*\"شیراز\" + -0.202*\"تعاون\" + 0.201*\"احیا\" + 0.198*\"میراث\" + 0.195*\"مرمت\" + 0.158*\"بافت\"\n",
      "----------\n",
      "0.416*\"بحرین\" + 0.248*\"اقتصاد\" + 0.220*\"مقاومت\" + 0.197*\"عیسی\" + 0.167*\"تعاون\" + 0.160*\"شیخ\" + 0.144*\"قاسم\" + 0.143*\"گردشگری\" + 0.110*\"تعاونی\" + -0.101*\"بیمارستان\"\n",
      "----------\n",
      "-0.270*\"اتحادیه\" + -0.248*\"انگلیس\" + -0.224*\"اروپا\" + 0.172*\"شیروان\" + 0.164*\"ع\" + 0.163*\"شهرستان\" + 0.158*\"بحرین\" + 0.156*\"بیمارستان\" + 0.119*\"اهل\" + 0.116*\"امام\"\n",
      "----------\n",
      "-0.251*\"شیروان\" + -0.236*\"بیمارستان\" + 0.227*\"ع\" + 0.171*\"زندان\" + 0.169*\"اهل\" + 0.160*\"بیت\" + 0.148*\"حرم\" + -0.142*\"شهرستان\" + -0.129*\"اعتبار\" + -0.129*\"هاشم\"\n",
      "----------\n",
      "0.412*\"زندان\" + 0.263*\"چهارمحال\" + 0.201*\"بختیار\" + 0.179*\"اتحادیه\" + 0.167*\"انگلیس\" + 0.142*\"اروپا\" + 0.140*\"سرمایه\" + 0.131*\"شهرکرد\" + 0.130*\"بدهی\" + 0.130*\"گردشگری\"\n",
      "----------\n",
      "0.222*\"اتحادیه\" + 0.198*\"انگلیس\" + -0.189*\"اردبیل\" + -0.186*\"زندان\" + 0.178*\"اروپا\" + 0.154*\"شیروان\" + 0.133*\"ع\" + -0.131*\"چهارمحال\" + 0.129*\"بیمارستان\" + -0.121*\"پرونده\"\n",
      "----------\n",
      "\n",
      "----------\n",
      "\n",
      "----------\n",
      "\n",
      "----------\n",
      "\n",
      "----------\n",
      "\n",
      "----------\n",
      "\n",
      "----------\n",
      "\n",
      "----------\n",
      "\n",
      "----------\n",
      "\n",
      "----------\n",
      "\n",
      "----------\n",
      "\n",
      "----------\n",
      "\n",
      "----------\n",
      "\n",
      "----------\n",
      "\n",
      "----------\n",
      "\n",
      "----------\n",
      "\n",
      "----------\n",
      "\n",
      "----------\n",
      "\n",
      "----------\n",
      "\n",
      "----------\n",
      "\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    print(lsi.print_topic(i))\n",
    "    print (\"----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['topic 0: 0.090* + 0.004*اقتصاد + 0.004*اورژانس + 0.003*اصفهان + 0.003*مقاومت + 0.003*سال + 0.002*پایگاه + 0.002*ترامپ + 0.002*نظر + 0.002*بیان',\n",
       " 'topic 1: 0.055* + 0.006*the + 0.003*and + 0.003*to + 0.003*that + 0.002*of + 0.002*in + 0.002*قانون + 0.002*ایران + 0.002*آمریکا',\n",
       " 'topic 2: 0.055* + 0.003*بحرین + 0.002*مواد + 0.002*حزب + 0.002*ورزش + 0.002*بیان + 0.002*پیشگیر + 0.002*استان + 0.002*بخش + 0.001*تعاون',\n",
       " 'topic 3: 0.060* + 0.004*سال + 0.003*استان + 0.003*اسناد + 0.002*ثبت + 0.002*کرمان + 0.002*فوتبال + 0.002*طرح + 0.002*گردشگری + 0.002*املاک']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> hdp = models.HdpModel(corpus, dictionary.id2token)\n",
    ">>> hdp.print_topics(topics=4, topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script src=\"https://d3js.org/d3.v4.min.js\"></script>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%javascript\n",
    "require.config({\n",
    "  paths: {\n",
    "      d3: '//cdnjs.cloudflare.com/ajax/libs/d3/3.4.8/d3.min'\n",
    "  }\n",
    "});\n",
    "element.append(\"<div id='chart1'></div>\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
