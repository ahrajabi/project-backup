{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import redis\n",
    "import time\n",
    "import numpy as np\n",
    "import lda\n",
    "import lda.datasets\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = redis.StrictRedis()\n",
    "swfa = pd.read_csv('../dataset/stopwords.csv' , header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82120000\n",
      "82120500\n",
      "82121000\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for i in range(82120000,82154440):#range(82120000,82154440):\n",
    "    if i % 500 == 0:\n",
    "        print(i)\n",
    "    if r.exists('irna#'+str(i)):\n",
    "        continue\n",
    "    url = 'http://www.irna.ir/fa/News/'+str(i)+'/'\n",
    "    page = requests.get(url).text\n",
    "    soup = bs(page , \"html.parser\")\n",
    "    if soup :\n",
    "        body = soup.find('div',class_='BodyText')\n",
    "        if body:\n",
    "            body = body.find('p')\n",
    "            r.set('irna#'+str(i) , body.text)\n",
    "        else:\n",
    "            r.set('irna#'+str(i) , \"None\")\n",
    "    else:\n",
    "        r.set('irna#'+str(i) , \"None\")\n",
    "print(\"--- %s seconds ---\" % ( time.time() - start_time ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "100\n",
      "--- 21.684365272521973 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "from hazm import *\n",
    "tagger = POSTagger(model='../dataset/tagger/postagger.model')\n",
    "clean_train = []\n",
    "clean_train_original = []\n",
    "cnt = 0\n",
    "for i in r.keys(pattern='irna#821200*'):\n",
    "    body = r.get(i)\n",
    "    cnt += 1\n",
    "    if cnt % 50 == 0:\n",
    "        print(cnt)\n",
    "    if body == 'None':\n",
    "        continue\n",
    "    body = body.decode('utf-8')\n",
    "#    print(body)\n",
    "    norm = Normalizer()\n",
    "    stemmer = Stemmer()\n",
    "    lemmatizer = Lemmatizer()\n",
    "    body = norm.normalize(body)\n",
    "    body = word_tokenize(body)\n",
    "    words = [w for w in body if not w in list(swfa[0])]\n",
    "    for idx , j in enumerate(words):\n",
    "#        words[idx] = stemmer.stem(j)\n",
    "        k = tagger.tag([words[idx]])\n",
    "#        print(k)\n",
    "        if k[0][1] in [\"PUNC\",\"NUM\",\"V\",\"ADV\",\"AJ\"] :\n",
    "            words[idx] = ''\n",
    "        words[idx] = lemmatizer.lemmatize(words[idx])\n",
    "        #print(tagger.tag(j))\n",
    "    clean_train_original.append(words)\n",
    "    clean_train.append( \" \".join( words ) )\n",
    "#    print(clean_train)\n",
    "\n",
    "print(\"--- %s seconds ---\" % ( time.time() - start_time ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 500)\n",
    "train_data_features_original = vectorizer.fit_transform(clean_train)\n",
    "train_data_features = train_data_features_original.toarray()\n",
    "vocab = vectorizer.get_feature_names()\n",
    "print(len(vocab))\n",
    "dist = np.sum(train_data_features, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lda.lda.LDA at 0x7f8e59a78b00>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lda.LDA(n_topics = 50 , n_iter=300, random_state=1)\n",
    "model.fit(train_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: دولت کشور حقوق نظام قانون جمهوری رئیس مدیر پرداخت\n",
      "Topic 1: افراد وجود کار سال زمان دلیل قرار دست فرد\n",
      "Topic 2: آمریکا روزنامه عنوان گزارش کره کشور خبر شبکه اعلام\n",
      "Topic 3: گروه عراق نیرو داعش سوریه شهر عملیات نظام گزارش\n",
      "Topic 4: آتش سوخت حادثه جاده نیرو روز ساعت علت زمین\n",
      "Topic 5: کشور توسعه سرمایه بخش ایجاد زمینه حوزه رشد فعالیت\n",
      "Topic 6: انقلاب رهبر الاسلام جمعه اشاره حجت امام الله جامعه\n",
      "Topic 7: خراسان قانون رضوی نامه نفر نظر ادامه کشور سازمان\n",
      "Topic 8: زندان کمک ریال جشن نفر خیر ستاد استان خانواده\n",
      "Topic 9: حزب انتخابات کار وزیر حضور حمایت رهبر روز سال\n",
      "Topic 10: استان ثبت سال سازمان انداز انداخت اداره انجام اظهار\n",
      "Topic 11: سال درصد گذشته اصفهان نفر افزایش میزان آمار حدود\n",
      "Topic 12: اسلام جهان مسلمان ادامه بیان ایران دشمن ملت روز\n",
      "Topic 13: بحرین رژیم آل شیخ قاسم عیسی خلیفه تابعیت کشور\n",
      "Topic 14: اتحادیه اروپا انگلیس خروج کشور پرس پرسید بریتانیا برگزیت\n",
      "Topic 15: کرمان سرباز فارس حادثه شیراز اتوبوس خوزستان نفر دستگاه\n",
      "Topic 16: منطقه نیرو دریا کشور چین نظام مناطق مرز سال\n",
      "Topic 17: استان استاندار بوشهر سمنان مدیرکل بیان مدیر نشست کشور\n",
      "Topic 18: تیم ورزش فوتبال لیگ باشگاه جوان فصل رشته هیات\n",
      "Topic 19: شهرستان روستا کیلومتر فرماندار نفر جمعیت آذربایجان واقع ایرنا\n",
      "Topic 20: تیم بازی رقابت دیدار مسابقات مرحله ایران های حضور\n",
      "Topic 21: محیط زیست none حفاظت استان گونه مدیرکل سازمان منطقه\n",
      "Topic 22: شب ماه رمضان قدر قرآن مبارک مراسم نماز امام\n",
      "Topic 23: شهر شهردار شهروند شورا فضا زمین منطقه حاشیه مدیریت\n",
      "Topic 24: آب استان کشاورزی هکتار مصرف منابع شرکت روستا اراضی\n",
      "Topic 25: وزیر رئیس کشور سفر جمهوری دیدار امور ترکیه فرانسه\n",
      "Topic 26: مواد مبارزه اعتیاد مصرف پیشگیر جامعه آسیب خانواده استان\n",
      "Topic 27: کاهش بازار درصد قیمت نرخ افزایش ریال دلار ارزش\n",
      "Topic 28: مجلس مازندران کمیسیون شورا نمایندگان نماینده دوره استان عضو\n",
      "Topic 29: کشور ها بحران مدیریت توجه اقدامات انجام قرار تاکید\n",
      "Topic 30: واحد بانک تسهیلات مسکن مشکلات استان پرداخت ریال مشکل\n",
      "Topic 31: پرونده دستگاه دادگستری قوه سال رسیدگی کاهش استان حقوق\n",
      "Topic 32: شهید شهدا شهادت روز قدس هفته انقلاب تیر قوه\n",
      "Topic 33: رسان رساند اطلاع پایگاه ایرنا روز گزارش روابط ها\n",
      "Topic 34: گردشگری دست ساخت صنایع ساز خانه ایجاد ظرفیت حوزه\n",
      "Topic 35: طرح اجرا پروژه سال ریال اعتبار بهره کار ساخت\n",
      "Topic 36: اقتصاد مقاومت برنامه دولت بخش طرح اجرا تحقق توسعه\n",
      "Topic 37: سازمان پاکستان کشور همکار هند شانگهای ایران عضو افغانستان\n",
      "Topic 38: آموزش دانش پرورش برنامه دوره نفر استان کانون فعالیت\n",
      "Topic 39: تهران روز ساعت ایرنا شرکت خبر برنامه شنبه گزارش\n",
      "Topic 40: دانشگاه قرآن نمایشگاه کتاب استاد موسسه علوم فرهنگ رشته\n",
      "Topic 41: کار فرهنگ جامعه رسانه تلاش نقش حوزه مسئول بیان\n",
      "Topic 42: روز هوا استان سیستان گذشته شرایط افزایش ایرنا متر\n",
      "Topic 43: پلیس خودرو قاچاق کالا کشف شناسایی فرمانده دستگاه شهرستان\n",
      "Topic 44: شرکت تولید صنعت صادرات کشور نفت بازار معدن محصولات\n",
      "Topic 45: کودک خانواده زن جوان جامعه فضا زندگی برنامه افراد\n",
      "Topic 46: امام حسن حضرت علی مراسم اهل بیت سید محمد\n",
      "Topic 47: ایران کشور روسیه المللی سال عربستان جهان جمهوری آمریکا\n",
      "Topic 48: سازمان شورا برنامه جلسه گزارش دستگاه کمیته نهاد ملل\n",
      "Topic 49: پزشک بیمار سلامت بهداشت قم بیمارستان درمان دانشگاه خون\n"
     ]
    }
   ],
   "source": [
    "topic_word = model.topic_word_  # model.components_ also works\n",
    "n_top_words = 10\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    np.array(vocab)[np.argsort(topic_dist)]\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-n_top_words:-1]\n",
    "    print('Topic {}: {}'.format(i, ' '.join(topic_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models , similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(clean_train_original)\n",
    "corpus = [dictionary.doc2bow(text) for text in clean_train_original]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.ldamodel.LdaModel at 0x7f8e593a7518>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.LdaModel(corpus, num_topics = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
